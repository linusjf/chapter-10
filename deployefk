#!/usr/bin/env bash
set -euo pipefail

RESOURCE_GROUP="${1:-flixtube}"
NAMESPACE="${2:-logging}"
CLUSTER_NAME="${RESOURCE_GROUP}" # default: same name as RG

show_help() {
  cat << EOF
Usage: $0 [RESOURCE_GROUP] [NAMESPACE]

Deploy EFK (Elasticsearch, Fluentd, Kibana) stack to an AKS cluster.

Defaults:
  RESOURCE_GROUP = flixtube
  NAMESPACE      = logging

Examples:
  $0
  $0 my-rg
  $0 my-rg my-namespace
EOF
}

if [[ "${1:-}" == "--help" ]]; then
  show_help
  exit 0
fi

for cmd in kubectl az helm; do
  if ! command -v "$cmd" > /dev/null 2>&1; then
    echo "‚ùå $cmd is not installed or not in PATH"
    exit 1
  fi
done

echo "‚õì Getting AKS credentials for RG='$RESOURCE_GROUP', cluster='$CLUSTER_NAME'..."
az aks get-credentials --resource-group "$RESOURCE_GROUP" --name "$CLUSTER_NAME" --overwrite-existing

echo "üîß Ensuring namespace '$NAMESPACE' exists..."
kubectl get ns "$NAMESPACE" > /dev/null 2>&1 || kubectl create ns "$NAMESPACE"

echo "‚öôÔ∏è Applying vm.max_map_count DaemonSet on all nodes..."
cat << 'EOF' | kubectl apply -f -
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: vm-max-map-count-setter
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app: vm-max-map-count-setter
  template:
    metadata:
      labels:
        app: vm-max-map-count-setter
    spec:
      hostPID: true
      containers:
      - name: sysctl
        image: busybox:latest
        securityContext:
          privileged: true
        command:
        - sh
        - -c
        - |
          echo "Setting vm.max_map_count=262144"
          sysctl -w vm.max_map_count=262144 || true
          sleep 3600
EOF

kubectl -n kube-system rollout status daemonset/vm-max-map-count-setter --timeout=120s \
  || echo "‚ö†Ô∏è vm.max_map_count DaemonSet rollout timed out; Elasticsearch may still work if node already compliant."

echo "üì¶ Adding Elastic Helm repo..."
helm repo add elastic https://helm.elastic.co > /dev/null 2>&1 || true
helm repo update

echo "üìå Deploying Elasticsearch (single node, no persistence: DEV MODE)..."
helm upgrade --install elasticsearch elastic/elasticsearch \
  --namespace "$NAMESPACE" \
  --create-namespace \
  --set replicas=1 \
  --set minimumMasterNodes=1 \
  --set persistence.enabled=false \
  --set resources.requests.cpu=200m \
  --set resources.requests.memory=1Gi \
  --set resources.limits.memory=2Gi

echo "‚è≥ Waiting for Elasticsearch pod to be Ready..."
# ES chart usually labels master pods with app=elasticsearch-master
kubectl -n "$NAMESPACE" wait --for=condition=ready pod \
  -l app=elasticsearch-master --timeout=600s

echo "üìå Deploying Kibana..."
helm upgrade --install kibana elastic/kibana \
  --namespace "$NAMESPACE" \
  --set elasticsearchHosts="http://elasticsearch-master:9200" \
  --set resources.requests.cpu=100m \
  --set resources.requests.memory=512Mi \
  --set resources.limits.memory=1Gi

echo "‚è≥ Waiting for Kibana to be Ready..."
kubectl -n "$NAMESPACE" rollout status deployment/kibana-kibana --timeout=600s

echo "üìå Deploying Fluentd DaemonSet (Elasticsearch output)..."
kubectl -n "$NAMESPACE" apply -f \
  https://raw.githubusercontent.com/fluent/fluentd-kubernetes-daemonset/master/fluentd-daemonset-elasticsearch.yaml

echo "‚è≥ Waiting for Fluentd pods to become Ready..."
kubectl -n "$NAMESPACE" wait --for=condition=ready pod \
  -l k8s-app=fluentd-logging --timeout=600s

echo "üîß Pointing Fluentd at elasticsearch-master:9200 (instead of default elasticsearch-logging)..."
kubectl -n "$NAMESPACE" set env daemonset/fluentd-elasticsearch \
  FLUENT_ELASTICSEARCH_HOST=elasticsearch-master \
  FLUENT_ELASTICSEARCH_PORT=9200

echo "üéâ EFK successfully deployed to namespace '$NAMESPACE' on AKS!"
echo
echo "üö™ Starting port-forwarding for local access (Ctrl+C to stop)..."
echo "  Kibana        ‚Üí http://localhost:5601"
echo "  Elasticsearch ‚Üí http://localhost:9200"
echo

kubectl -n "$NAMESPACE" port-forward svc/kibana-kibana 5601:5601 \
  svc/elasticsearch-master 9200:9200
